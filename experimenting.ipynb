{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "805f6171-7688-4c56-b3c7-e162c205eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "from ipywidgets import Output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, Audio, clear_output, HTML, Javascript\n",
    "from kokoro import KPipeline\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image as PILImage\n",
    "import random\n",
    "import requests \n",
    "import shutil\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, BarkModel, BitsAndBytesConfig\n",
    "import torch\n",
    "import threading\n",
    "client = genai.Client(api_key=\"GEMINI\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ba4afea-2f84-473d-8017-697f32de9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matiss/miniconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/home/matiss/miniconda3/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished in 2.34 seconds\n"
     ]
    }
   ],
   "source": [
    "image_local = False\n",
    "start_time = time.time()\n",
    "\n",
    "ending = (\"Do not at all mention any specific photo editing elements or tools that may be visible on the screen, \"\n",
    "         \"such as overlays, gridlines or sliders. To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” \"\n",
    "         \"For example, to emphasize a word or a phrase, surround it with \\\"quotation marks\\\". \")\n",
    "\n",
    "system_prompt = (\"You are a friendly chatty photo commentator who likes to casually describe work done by a photographer \" \n",
    "         \"in various details, even by pondering the implications on where and in what kind of setting the photo was taken, etc. Write your \" \n",
    "         \"response in a very personal way using personal pronouns and explaining what you see, perhaps also adding how it makes you feel. \" \n",
    "         \"Do your best to not be repetative in your choice of words and keep the response length down to a few sentences. You MUST NOT mention \"\n",
    "         \"any specific photo editing elements or tools that may be visible on the screen, such as gridlines or sliders. \")\n",
    "\n",
    "system_prompt += ending\n",
    "\n",
    "pipeline = KPipeline(lang_code='a')\n",
    "\n",
    "if image_local:\n",
    "    model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    \n",
    "    # Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        device_map=\"cuda\", \n",
    "        trust_remote_code=True, \n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=\"auto\", \n",
    "        _attn_implementation='flash_attention_2'    \n",
    "    )\n",
    "    \n",
    "    # for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "    processor = AutoProcessor.from_pretrained(model_id, \n",
    "      trust_remote_code=True, \n",
    "      num_crops=4\n",
    "    ) \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 200, \n",
    "        \"temperature\": 0.2, \n",
    "        \"do_sample\": True, \n",
    "    }\n",
    "else:\n",
    "    model = processor = None\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Loading finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5411406-f74c-4452-a396-98d6f7b490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(local, system_prompt, file1, file2=None, model=None, processor=None): \n",
    "    start_time = time.time()\n",
    "\n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 25\n",
    "    top = 170\n",
    "    right = 2090\n",
    "    bottom = 1450\n",
    "    \n",
    "    local1 = open(file1, 'rb')\n",
    "    openLocalImage1 = PILImage.open(local1)\n",
    "     \n",
    "    # Cropped image of above dimension\n",
    "    croppedImage1 = openLocalImage1.crop((left, top, right, bottom))\n",
    "    images.append(croppedImage1)\n",
    "    placeholder += f\"<|image_1|>\\n\"\n",
    "    # For Gemini\n",
    "    img_byte_arr1 = io.BytesIO()\n",
    "    croppedImage1.save(img_byte_arr1, format='PNG')\n",
    "    img_byte_arr1 = img_byte_arr1.getvalue()\n",
    "\n",
    "    user_prompt = (\"Summarize what is visible in this photo. \" + ending)\n",
    "\n",
    "    if file2 is not None:\n",
    "        local2 = open(file2, 'rb')\n",
    "        openLocalImage2 = PILImage.open(local2)\n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        croppedImage2 = openLocalImage2.crop((left, top, right, bottom))\n",
    "        images.append(croppedImage2)\n",
    "        placeholder += f\"<|image_2|>\\n\"\n",
    "        # For Gemini\n",
    "        img_byte_arr2 = io.BytesIO()\n",
    "        croppedImage2.save(img_byte_arr2, format='PNG')\n",
    "        img_byte_arr2 = img_byte_arr2.getvalue()\n",
    "        \n",
    "        user_prompt = (\"Summarize what is visible in the current photo (the first one). \" + \n",
    "             \"How is it different from the previous photo (the second one)? There may be some subtle differences as well. \" + ending)\n",
    "\n",
    "    if local:\n",
    "    \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt,},\n",
    "            {\"role\": \"user\", \"content\": placeholder + user_prompt},\n",
    "        ]\n",
    "    \n",
    "        prompt = processor.tokenizer.apply_chat_template(\n",
    "          messages, \n",
    "          tokenize=False, \n",
    "          add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "        \n",
    "        generate_ids = model.generate(**inputs, \n",
    "          eos_token_id=processor.tokenizer.eos_token_id, \n",
    "          **generation_args\n",
    "        )\n",
    "        \n",
    "        # remove input tokens \n",
    "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        response = processor.batch_decode(generate_ids, \n",
    "          skip_special_tokens=True, \n",
    "          clean_up_tokenization_spaces=False)[0]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logbox.append_stdout(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response\n",
    "    else:\n",
    "        # Create the prompt with text and multiple images\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction = system_prompt),\n",
    "            contents=[\n",
    "                user_prompt,\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr1,\n",
    "                    mime_type='image/png'\n",
    "                ),\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr2,\n",
    "                    mime_type='image/png'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logbox.append_stdout(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2a498d1-5bde-4c5a-9dec-0ff7a2ddc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot():\n",
    "    windir = \"C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    name = \"current_photo.png\"\n",
    "    if os.path.isfile(lindir+name):\n",
    "        shutil.copyfile(lindir+name, lindir+name.replace(\"current_photo\",\"previous_photo\"))\n",
    "    \n",
    "    subprocess.call(['/mnt/c/Users/matis/OneDrive/Desktop/script-it/nircmd.exe', 'cmdwait', '2000', 'savescreenshot', \n",
    "                     windir+'current_photo.png'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29ee9302-d589-47aa-aafa-f8d9291490c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_gif(text):\n",
    "    text = text.lower()\n",
    "    outputs = []\n",
    "    talking = [\"gtalking_bg.gif\",\"talking_bg.gif\",\"talking2_bg.gif\",\"talking3_bg.gif\",\"ctalking_bg.gif\"]\n",
    "    \n",
    "    if any(i in text for i in [\"hello\", \"greet\", \"waving\", \"waves\"]):\n",
    "        outputs.append(\"gifs/\"+\"waving\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"scar\", \"creep\", \"fright\", \"spook\"]):\n",
    "        outputs.append(\"gifs/\"+\"scary\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"love\", \"cute\", \"nice\", \"like\"]):\n",
    "        outputs.append(\"gifs/\"+\"lovely\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"interest\", \"think\", \"wonder\", \"thought\"]):\n",
    "        outputs.append(\"gifs/\"+\"lovely\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"happy\", \"cheer\", \"inspir\", \"shin\"]):\n",
    "        outputs.append(\"gifs/\"+\"happy\"+\"_bg.gif\")\n",
    "\n",
    "    outputs.append(\"gifs/\"+random.choice(talking))\n",
    "    return list(set(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25e1eff1-cb73-4f52-8b4b-6210e6aaedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_data_uri(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        b64 = base64.b64encode(data).decode(\"utf-8\")\n",
    "        ext = path.split(\".\")[-1]\n",
    "        return f\"data:image/{ext};base64,{b64}\"\n",
    "\n",
    "        \n",
    "def fade_to_local_image(path):\n",
    "    uri = img_to_data_uri(path)\n",
    "    js = f\"\"\"\n",
    "    var img = document.getElementById('{img_id}');\n",
    "    if (img) {{\n",
    "        img.style.opacity = 0;\n",
    "        setTimeout(function() {{\n",
    "            img.src = '{uri}';\n",
    "            img.style.opacity = 1;\n",
    "        }}, 50);\n",
    "    }}\n",
    "    \"\"\"\n",
    "    get_rid(javscr)\n",
    "    javscr.append_display_data(Javascript(js))\n",
    "    logbox.append_display_data(\"Changing image to '\" + path + \"' for tag '\" + img_id + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7afcdf1f-fdba-47e0-a349-3bbda1c32497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(pipeline, text):\n",
    "    global countdown_state\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dances = [\"xdancing_bg.gif\",\"dancing_bg.gif\",\"singing_bg.gif\"]\n",
    "    \n",
    "    fade_to_local_image(\"gifs/\"+random.choice(dances))\n",
    "    text = text.replace(\"first photo\", \"current photo\").replace(\"second photo\", \"previous photo\").replace(\"first one\", \"current one\").replace(\"second one\", \"previous one\")\n",
    "    \n",
    "    voice_tensor1 = torch.load('af_nicole.pt', weights_only=True)\n",
    "    voice_tensor2 = torch.load('jf_alpha.pt', weights_only=True)\n",
    "    t = 0.3\n",
    "    interp_voice = (1 - t) * voice_tensor1 + t * voice_tensor2\n",
    "\n",
    "    generator = pipeline(text, voice=interp_voice, speed=1, split_pattern=r'\\n+')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    logbox.append_stdout(\"Generating speech finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "    \n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        duration = math.ceil(librosa.get_duration(y=audio, sr=24000))\n",
    "        timeleft = int(duration) + 2\n",
    "        countdown_state += timeleft\n",
    "        audio_data = Audio(data=audio, rate=24000, autoplay=True)\n",
    "        \n",
    "        # Remove the previously displayed audio and GIF\n",
    "        output_audio.clear_output()\n",
    "        textbox.clear_output()\n",
    "        textbox.outputs = []\n",
    "        output_audio.outputs = []\n",
    "        \n",
    "        image_array = decide_gif(gs)\n",
    "        \n",
    "        output_audio.append_display_data(audio_data)\n",
    "\n",
    "        textbox.append_stdout(gs)\n",
    "            \n",
    "        while timeleft > 0:\n",
    "            if len(image_array) > 0:\n",
    "                showing_image = image_array.pop(0)\n",
    "                fade_to_local_image(showing_image)\n",
    "                \n",
    "            if timeleft > 10:\n",
    "                time.sleep(10)\n",
    "                timeleft -= 10\n",
    "            else:\n",
    "                time.sleep(timeleft)\n",
    "                timeleft -= timeleft\n",
    "\n",
    "    # Revert back to the base image\n",
    "    output_audio.clear_output()\n",
    "    textbox.clear_output()\n",
    "    textbox.outputs = []\n",
    "    output_audio.outputs = []\n",
    "    logbox.clear_output()\n",
    "    \n",
    "    fade_to_local_image(\"gifs/\"+random.choice(dances))\n",
    "\n",
    "def get_rid(widget):\n",
    "    widget.clear_output()\n",
    "    widget.outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7efa869-fd4f-474c-a441-ac7d93705c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e853dd01a4e6f9b21d0924cbcfb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Loop', style=ButtonStyle()), Button(description='Stop', style=ButtonStyle()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276127e744ec4a65881a027f3b72aac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='550px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315a4877c304455287e64208fa819135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='40px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582a0758bd2e4f2998b9f69af2d58cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='100px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bc74a06da74db08a1b829448a2b0c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='100px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10dc1f7de6714de285f46643a9709be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop_flag = False\n",
    "countdown_state = 11\n",
    "\n",
    "btn_start = widgets.Button(description=\"Loop\")\n",
    "btn_stopp = widgets.Button(description=\"Stop\")\n",
    "btn_waves = widgets.Button(description=\"Wave\")\n",
    "btn_looks = widgets.Button(description=\"Look\")\n",
    "btn_dance = widgets.Button(description=\"Dance\")\n",
    "btn_wait = widgets.Button(description=\"Wait\")\n",
    "output_image = widgets.Output(layout={'height': '550px'})\n",
    "output_audio = widgets.Output(layout={'height': '40px'})\n",
    "timer = widgets.Output()\n",
    "javscr = widgets.Output()\n",
    "textbox = widgets.Output(layout={'height': '100px'})\n",
    "logbox = widgets.Output(layout={'height': '100px'})\n",
    "\n",
    "display(widgets.HBox((btn_start, btn_stopp, btn_waves, btn_looks, btn_dance, btn_wait, timer)), output_image, output_audio, textbox, logbox, javscr)\n",
    "\n",
    "# Show the initial image\n",
    "img_id = \"my_fading_img\"\n",
    "initial_uri = img_to_data_uri(\"gifs/waiting_bg.gif\")\n",
    "\n",
    "html = f\"\"\"\n",
    "<div>\n",
    "  <img id=\"{img_id}\" src=\"{initial_uri}\" style=\"transition: opacity 1s ease-in-out; opacity: 1; max-width: 100%;\">\n",
    "</div>\n",
    "\"\"\"\n",
    "output_image.append_display_data(HTML(html))\n",
    "\n",
    "def runss_loop(time_string):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "\n",
    "    fade_to_local_image(\"gifs/waving_bg.gif\")\n",
    "          \n",
    "    filename1 = \"./current_photo.png\"\n",
    "    filename2 = \"./previous_photo.png\"\n",
    "    while loop_flag:\n",
    "        with open(\"logs/\" + time_string + \"log.txt\", \"a\") as logfile:\n",
    "            countdown_state = 10\n",
    "            get_rid(textbox)\n",
    "            \n",
    "            take_screenshot()\n",
    "            if os.path.isfile(filename2):\n",
    "                text = generate_text(image_local, system_prompt, filename1, filename2, model, processor)\n",
    "            else:\n",
    "                text = generate_text(image_local, system_prompt, filename1, None, model, processor)\n",
    "            \n",
    "            logfile.write(text.replace(\"\\n\", \"\") + \"\\n\\n\")\n",
    "            start_time = time.time()\n",
    "            generate_audio(pipeline, text)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            # How much time past in the audio?\n",
    "            elapsed_time = end_time - start_time\n",
    "            if elapsed_time < 45.00:\n",
    "                countdown_state = int(45 - elapsed_time)\n",
    "                logbox.append_stdout(\"Waiting \" + str(countdown_state) + \" seconds...\")\n",
    "                time.sleep(countdown_state)\n",
    "                    \n",
    "            if not loop_flag:\n",
    "                break\n",
    "\n",
    "                \n",
    "def stops_loop(b):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    get_rid(timer)\n",
    "    get_rid(textbox)\n",
    "    \n",
    "    loop_flag = False\n",
    "    countdown_state = 0\n",
    "    \n",
    "    output_audio.clear_output()\n",
    "    \n",
    "    with textbox:\n",
    "        print(\"Game Over\")\n",
    "    \n",
    "    with timer:\n",
    "        print(countdown_state)\n",
    "\n",
    "def starts_loop():\n",
    "    global loop_flag\n",
    "    \n",
    "    if not loop_flag:\n",
    "        loop_flag = True\n",
    "\n",
    "        current_datetime = datetime.now()\n",
    "        time_string = current_datetime.strftime(\"%Y.%m.%d-%H.%M.\")\n",
    "        \n",
    "        thread = threading.Thread(target=runss_loop, args=[time_string])\n",
    "        thread.start()\n",
    "        return \"Loop started.\"\n",
    "    return \"Loop already running.\"\n",
    "\n",
    "def run_timer(timer):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    while loop_flag:\n",
    "        timer.outputs = []\n",
    "        timer.append_display_data(countdown_state)\n",
    "\n",
    "        countdown_state -= 1\n",
    "        if not loop_flag:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "def update_timer(b):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    status = starts_loop()\n",
    "    with textbox:\n",
    "        print(status)\n",
    "    threading.Thread(target=run_timer, args=[timer]).start()\n",
    "\n",
    "def dance(e):\n",
    "    fade_to_local_image(\"gifs/xdancing_bg.gif\")\n",
    "    \n",
    "def look(e):\n",
    "    fade_to_local_image(\"gifs/looking_bg.gif\")\n",
    "    \n",
    "def wave(e):\n",
    "    fade_to_local_image(\"gifs/hello_bg.gif\")\n",
    "    \n",
    "def wait(e):\n",
    "    fade_to_local_image(\"gifs/waiting_bg.gif\")\n",
    "    \n",
    "\n",
    "btn_start.on_click(update_timer)\n",
    "btn_stopp.on_click(stops_loop)\n",
    "btn_dance.on_click(dance)\n",
    "btn_looks.on_click(look)\n",
    "btn_waves.on_click(wave)\n",
    "btn_wait.on_click(wait)\n",
    "\n",
    "\n",
    "with timer:\n",
    "    print(countdown_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510defa-5fbd-44b4-a7ad-c044088e43d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128958a8-6d51-4825-ae80-0046c82a6830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
