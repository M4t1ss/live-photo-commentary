{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805f6171-7688-4c56-b3c7-e162c205eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import requests \n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, BarkModel, BitsAndBytesConfig\n",
    "import subprocess\n",
    "from IPython.display import Audio\n",
    "import scipy\n",
    "import os\n",
    "import shutil\n",
    "import os.path\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import time\n",
    "from IPython.display import display, Audio\n",
    "from kokoro import KPipeline\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba4afea-2f84-473d-8017-697f32de9c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6e72de90794837b379964a5e06a845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/x/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:517: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/x/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/home/matt/x/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "# Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"cuda\", \n",
    "    trust_remote_code=True, \n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=\"auto\", \n",
    "    _attn_implementation='flash_attention_2'    \n",
    ")\n",
    "\n",
    "# for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "processor = AutoProcessor.from_pretrained(model_id, \n",
    "  trust_remote_code=True, \n",
    "  num_crops=4\n",
    ") \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 1000, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "system_prompt = (\"You are a friendly chatty photo commentator who likes to casually describe work done by a photographer \" \n",
    "         \"in various details, even by pondering the implications on where and in what kind of setting the photo was taken, etc. Write your \" \n",
    "         \"response in a very personal way using personal pronouns and explaining what you see, perhaps also adding how it makes you feel. \" \n",
    "         \"To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” or stress ˈ and ˌ . \"\n",
    "         \"For more dramatic effects use symbols such as — or … for hesitations, and word capitalization for more emphasis.\")\n",
    "\n",
    "pipeline = KPipeline(lang_code='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5411406-f74c-4452-a396-98d6f7b490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_one(model, processor, system_prompt, file): #\"/mnt/c/Users/matis/OneDrive/Desktop/script-it/shot2.png\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    \n",
    "    local = open(lindir+file, 'rb')\n",
    "    openLocalImage = Image.open(local)\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 25\n",
    "    top = 170\n",
    "    right = 2090\n",
    "    bottom = 1450\n",
    "     \n",
    "    # Cropped image of above dimension\n",
    "    croppedImage = openLocalImage.crop((left, top, right, bottom))\n",
    "    \n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    images.append(croppedImage)\n",
    "    placeholder += f\"<|image_1|>\\n\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt,},\n",
    "        {\"role\": \"user\", \"content\": placeholder+\"Summarize what is visible in this photo. \" + \n",
    "         \"To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” or stress ˈ and ˌ . \" + \n",
    "         \"For more dramatic effects use symbols such as — or … for hesitations, and word capitalization for more emphasis.\"},\n",
    "    ]\n",
    "    \n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "      messages, \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    \n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response\n",
    "\n",
    "def generate_text_two(model, processor, system_prompt, file1, file2): #\"/mnt/c/Users/matis/OneDrive/Desktop/script-it/shot2.png\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    \n",
    "    local1 = open(lindir+file1, 'rb')\n",
    "    local2 = open(lindir+file2, 'rb')\n",
    "    openLocalImage1 = Image.open(local1)\n",
    "    openLocalImage2 = Image.open(local2)\n",
    "\n",
    "    \n",
    "    # Compare two images pixel by pixel\n",
    "    img1 = np.array(openLocalImage1)\n",
    "    img2 = np.array(openLocalImage2)\n",
    "    \n",
    "    # Check if the shapes are the same and pixels are identical\n",
    "    if img1.shape == img2.shape and np.all(img1 == img2):\n",
    "        identical = True\n",
    "    else:\n",
    "        identical = False\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 25\n",
    "    top = 170\n",
    "    right = 2090\n",
    "    bottom = 1450\n",
    "     \n",
    "    # Cropped image of above dimension\n",
    "    croppedImage1 = openLocalImage1.crop((left, top, right, bottom))\n",
    "    croppedImage2 = openLocalImage2.crop((left, top, right, bottom))\n",
    "    \n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    images.append(croppedImage1)\n",
    "    images.append(croppedImage2)\n",
    "    placeholder += f\"<|image_1|>\\n\"\n",
    "    placeholder += f\"<|image_2|>\\n\"\n",
    "\n",
    "    if not identical:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt,},\n",
    "            {\"role\": \"user\", \"content\": placeholder+\"Summarize what is visible in the current photo (the first one). \" + \n",
    "             \"How is it different from the previous photo (the second one)? There may be some subtle differences as well. \" + \n",
    "             \"To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” or stress ˈ and ˌ . \" + \n",
    "             \"For more dramatic effects use symbols such as — or … for hesitations, and word capitalization for more emphasis.\"},\n",
    "        ]\n",
    "    else:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt,},\n",
    "            {\"role\": \"user\", \"content\": placeholder+\"Summarize what is visible in the current photo (the first one). \" + \n",
    "             \"It seems like he is still working on the same photo or took a break from editing. \" + \n",
    "             \"To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” or stress ˈ and ˌ . \" + \n",
    "             \"For more dramatic effects use symbols such as — or … for hesitations, and word capitalization for more emphasis.\"},\n",
    "        ]\n",
    "    \n",
    "    prompt = processor.tokenizer.apply_chat_template(\n",
    "      messages, \n",
    "      tokenize=False, \n",
    "      add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "    \n",
    "    generate_ids = model.generate(**inputs, \n",
    "      eos_token_id=processor.tokenizer.eos_token_id, \n",
    "      **generation_args\n",
    "    )\n",
    "    \n",
    "    # remove input tokens \n",
    "    generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "    response = processor.batch_decode(generate_ids, \n",
    "      skip_special_tokens=True, \n",
    "      clean_up_tokenization_spaces=False)[0] \n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a498d1-5bde-4c5a-9dec-0ff7a2ddc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot():\n",
    "    windir = \"C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    name = \"shot.png\"\n",
    "    if os.path.isfile(lindir+name):\n",
    "        shutil.copyfile(lindir+name, lindir+name.replace(\"shot\",\"shot_prev\"))\n",
    "    \n",
    "    subprocess.call(['/mnt/c/Users/matis/OneDrive/Desktop/script-it/nircmd.exe', 'cmdwait', '2000', 'savescreenshot', \n",
    "                     windir+'shot.png'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7afcdf1f-fdba-47e0-a349-3bbda1c32497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_audio(pipeline, text):\n",
    "\n",
    "    text = text.replace(\"first photo\", \"current photo\")\n",
    "    text = text.replace(\"second photo\", \"previous photo\")\n",
    "    \n",
    "    windir = \"C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    playlist = \"#EXTM3U\\r\\n\\r\\n\"\n",
    "    \n",
    "    # prints a random value from the list\n",
    "    list1 = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\"]\n",
    "    letter = random.choice(list1)\n",
    "\n",
    "    generator = pipeline(text, voice='af_nicole')\n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        print(i, gs)\n",
    "        # display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
    "        sf.write(f'{str(i)+letter}.wav', audio, 24000)\n",
    "        stri = str(i)+letter\n",
    "        playlist += \"#EXTINF:\"+stri+\", Sample artist - Sample title\"+stri+\"\\r\\n\"\n",
    "        playlist += windir+stri+\".wav\\r\\n\\r\\n\"\n",
    "\n",
    "    \n",
    "    with open(lindir+\"list.m3u\", \"w\") as f:\n",
    "        f.write(playlist)\n",
    "    \n",
    "    subprocess.Popen(['/mnt/c/Program Files (x86)/Windows Media Player/wmplayer.exe', '/play', '/close', windir+\"list.m3u\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76912ffc-d578-4d70-8ce7-5041bbc1b34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The current photo captures a serene scene of a sleek, modern yacht gently gliding on the water's surface. The yacht is positioned centrally in the frame, with the calm water reflecting the clear blue sky and the towering skyscrapers in the background. The architecture of the buildings is contemporary, with clean lines and a minimalist design. The sky is a canvas of soft clouds, adding a dreamy quality to the image. The overall atmosphere is one of tranquility and luxury.\n",
      "1 In contrast, the previous photo depicts a bustling scene on a yacht. The yacht is adorned with a white canopy and is surrounded by a group of people, some of whom are seated and others standing, all appearing to be enjoying the day. The water is choppy, indicating movement and activity. The background shows a construction site with scaffolding and a building under construction, suggesting a more urban and dynamic environment. The sky is overcast, giving the image a more dramatic and vibrant feel.\n",
      "2 The current photo exudes a sense of calm and elegance, while the previous photo is lively and energetic. The current photo's setting is more natural and open, whereas the previous photo's setting is more man-made and busy. The current photo's yacht is alone and majestic, while the previous photo's yacht is shared and social. The current photo's mood is peaceful, while the previous photo's mood is spirited.\n",
      "Waiting...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m generate_audio(pipeline, text)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    filename1 = \"shot.png\"\n",
    "    filename2 = \"shot_prev.png\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "    \n",
    "    take_screenshot()\n",
    "    if os.path.isfile(lindir+filename2):\n",
    "        text = generate_text_two(model, processor, system_prompt, filename1, filename2)\n",
    "    else:\n",
    "        text = generate_text_one(model, processor, system_prompt, filename1)\n",
    "    \n",
    "    generate_audio(pipeline, text)\n",
    "\n",
    "    print(\"Waiting...\")\n",
    "    time.sleep(35) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c6bb0-088f-43da-8d14-86b1338b307b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fe5661-2c78-4daa-8922-59938dc62632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['/mnt/c/Program Files (x86)/Windows Media Pl...>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(['/mnt/c/Program Files (x86)/Windows Media Player/wmplayer.exe', '/play', '/close', 'C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\list.m3u'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
