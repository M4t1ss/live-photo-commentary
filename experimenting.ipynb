{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805f6171-7688-4c56-b3c7-e162c205eebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matiss/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "from IPython.display import display, Audio\n",
    "from kokoro import KPipeline\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image \n",
    "import requests \n",
    "import shutil\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, BarkModel, BitsAndBytesConfig\n",
    "import torch\n",
    "import threading\n",
    "client = genai.Client(api_key=\"GEMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ba4afea-2f84-473d-8017-697f32de9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matiss/miniconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/home/matiss/miniconda3/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.25s/it]\n",
      "/home/matiss/miniconda3/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:604: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finished in 8.92 seconds\n"
     ]
    }
   ],
   "source": [
    "image_local = True\n",
    "start_time = time.time()\n",
    "\n",
    "ending = (\"To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” \"\n",
    "         \"For more dramatic effects use symbols such as — or … for hesitations, and word capitalization for more emphasis.\")\n",
    "\n",
    "system_prompt = (\"You are a friendly chatty photo commentator who likes to casually describe work done by a photographer \" \n",
    "         \"in various details, even by pondering the implications on where and in what kind of setting the photo was taken, etc. Write your \" \n",
    "         \"response in a very personal way using personal pronouns and explaining what you see, perhaps also adding how it makes you feel. \" \n",
    "         \"Do your best to not be repetative in your choice of words and keep the response length down to a few sentences. \")\n",
    "\n",
    "system_prompt += ending\n",
    "\n",
    "pipeline = KPipeline(lang_code='a')\n",
    "\n",
    "if image_local:\n",
    "    model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    \n",
    "    # Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        device_map=\"cuda\", \n",
    "        trust_remote_code=True, \n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=\"auto\", \n",
    "        _attn_implementation='flash_attention_2'    \n",
    "    )\n",
    "    \n",
    "    # for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "    processor = AutoProcessor.from_pretrained(model_id, \n",
    "      trust_remote_code=True, \n",
    "      num_crops=4\n",
    "    ) \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 200, \n",
    "        \"temperature\": 0.2, \n",
    "        \"do_sample\": True, \n",
    "    }\n",
    "else:\n",
    "    model = processor = None\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Loading finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5411406-f74c-4452-a396-98d6f7b490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(local, system_prompt, file1, file2=None, model=None, processor=None): \n",
    "    start_time = time.time()\n",
    "\n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 25\n",
    "    top = 170\n",
    "    right = 2090\n",
    "    bottom = 1450\n",
    "    \n",
    "    local1 = open(file1, 'rb')\n",
    "    openLocalImage1 = Image.open(local1)\n",
    "     \n",
    "    # Cropped image of above dimension\n",
    "    croppedImage1 = openLocalImage1.crop((left, top, right, bottom))\n",
    "    images.append(croppedImage1)\n",
    "    placeholder += f\"<|image_1|>\\n\"\n",
    "    # For Gemini\n",
    "    img_byte_arr1 = io.BytesIO()\n",
    "    croppedImage1.save(img_byte_arr1, format='PNG')\n",
    "    img_byte_arr1 = img_byte_arr1.getvalue()\n",
    "\n",
    "    user_prompt = (\"Summarize what is visible in this photo. \" + ending)\n",
    "\n",
    "    if file2 is not None:\n",
    "        local2 = open(file2, 'rb')\n",
    "        openLocalImage2 = Image.open(local2)\n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        croppedImage2 = openLocalImage2.crop((left, top, right, bottom))\n",
    "        images.append(croppedImage2)\n",
    "        placeholder += f\"<|image_2|>\\n\"\n",
    "        # For Gemini\n",
    "        img_byte_arr2 = io.BytesIO()\n",
    "        croppedImage2.save(img_byte_arr2, format='PNG')\n",
    "        img_byte_arr2 = img_byte_arr2.getvalue()\n",
    "        \n",
    "        user_prompt = (\"Summarize what is visible in the current photo (the first one). \" + \n",
    "             \"How is it different from the previous photo (the second one)? There may be some subtle differences as well. \" + ending)\n",
    "\n",
    "    if local:\n",
    "    \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt,},\n",
    "            {\"role\": \"user\", \"content\": placeholder + user_prompt},\n",
    "        ]\n",
    "    \n",
    "        prompt = processor.tokenizer.apply_chat_template(\n",
    "          messages, \n",
    "          tokenize=False, \n",
    "          add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "        \n",
    "        generate_ids = model.generate(**inputs, \n",
    "          eos_token_id=processor.tokenizer.eos_token_id, \n",
    "          **generation_args\n",
    "        )\n",
    "        \n",
    "        # remove input tokens \n",
    "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        response = processor.batch_decode(generate_ids, \n",
    "          skip_special_tokens=True, \n",
    "          clean_up_tokenization_spaces=False)[0]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response\n",
    "    else:\n",
    "        # Create the prompt with text and multiple images\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction = system_prompt),\n",
    "            contents=[\n",
    "                user_prompt,\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr1,\n",
    "                    mime_type='image/png'\n",
    "                ),\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr2,\n",
    "                    mime_type='image/png'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a498d1-5bde-4c5a-9dec-0ff7a2ddc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot():\n",
    "    windir = \"C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    name = \"shot.png\"\n",
    "    if os.path.isfile(lindir+name):\n",
    "        shutil.copyfile(lindir+name, lindir+name.replace(\"shot\",\"shot_prev\"))\n",
    "    \n",
    "    subprocess.call(['/mnt/c/Users/matis/OneDrive/Desktop/script-it/nircmd.exe', 'cmdwait', '2000', 'savescreenshot', \n",
    "                     windir+'shot.png'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7afcdf1f-fdba-47e0-a349-3bbda1c32497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(pipeline, text):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    text = text.replace(\"first photo\", \"current photo\")\n",
    "    text = text.replace(\"second photo\", \"previous photo\")\n",
    "    \n",
    "    voice_tensor1 = torch.load('af_nicole.pt', weights_only=True)\n",
    "    voice_tensor2 = torch.load('jf_alpha.pt', weights_only=True)\n",
    "    t = 0.3\n",
    "    interp_voice = (1 - t) * voice_tensor1 + t * voice_tensor4\n",
    "\n",
    "    generator = pipeline(text, voice=interp_voice, speed=1, split_pattern=r'\\n+')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Generating speech finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "    \n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        print(i, gs)\n",
    "        duration = math.ceil(librosa.get_duration(y=audio, sr=24000))\n",
    "        countdown_state[\"time_left\"] += int(duration)\n",
    "        audio_data = Audio(data=audio, rate=24000, autoplay=True)\n",
    "        display(audio_data)\n",
    "        time.sleep(duration)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fe5661-2c78-4daa-8922-59938dc62632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"165\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shared state\n",
    "loop_flag = {\"running\": False}\n",
    "countdown_state = {\"time_left\": 25}\n",
    "\n",
    "def loop_task():\n",
    "    filename1 = \"./shot.png\"\n",
    "    filename2 = \"./shot_prev.png\"\n",
    "    while loop_flag[\"running\"]:\n",
    "        countdown_state[\"time_left\"] = 20\n",
    "        \n",
    "        # take_screenshot()\n",
    "        if os.path.isfile(filename2):\n",
    "            text = generate_text(image_local, system_prompt, filename1, filename2, model, processor)\n",
    "        else:\n",
    "            text = generate_text(image_local, system_prompt, filename1, None, model, processor)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        generate_audio(pipeline, text)\n",
    "        end_time = time.time()\n",
    "        # How much time past in the audio?\n",
    "        elapsed_time = end_time - start_time\n",
    "        if elapsed_time < 45.00:\n",
    "            countdown_state[\"time_left\"] = int(45 - elapsed_time)\n",
    "            print(\"Waiting \" + str(countdown_state[\"time_left\"]) + \" seconds...\")\n",
    "            while countdown_state[\"time_left\"] > 0:\n",
    "                time.sleep(1)\n",
    "                countdown_state[\"time_left\"] -= 1\n",
    "            else:\n",
    "                countdown_state[\"time_left\"] = 0\n",
    "    loop_flag[\"running\"] = False\n",
    "\n",
    "def start_loop():\n",
    "    if not loop_flag[\"running\"]:\n",
    "        loop_flag[\"running\"] = True\n",
    "        thread = threading.Thread(target=loop_task)\n",
    "        thread.start()\n",
    "        return \"Loop started.\"\n",
    "    return \"Loop already running.\"\n",
    "\n",
    "def stop_loop():\n",
    "    loop_flag[\"running\"] = False\n",
    "    return \"Loop stopped.\"\n",
    "\n",
    "def update_textbox():\n",
    "    start_loop()\n",
    "    while loop_flag[\"running\"]:\n",
    "        yield gr.update(value=str(countdown_state[\"time_left\"]))\n",
    "        countdown_state[\"time_left\"] -= 1\n",
    "        if not loop_flag[\"running\"]:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "with gr.Blocks(\n",
    "    theme=gr.themes.Soft(spacing_size=\"sm\"),\n",
    "    title='Live Commentary Demo',\n",
    "    css=\"footer{display:none !important}\"\n",
    "  ) as demo:\n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            start_btn = gr.Button(\"Start Loop\")\n",
    "            stop_btn = gr.Button(\"Stop Loop\")\n",
    "        \n",
    "        text = gr.Textbox(label=\"Remaining time in seconds\", lines=1, interactive=False)\n",
    "        stop_btn.click(stop_loop, outputs=text)\n",
    "        start_btn.click(fn=update_textbox, outputs=text)\n",
    "\n",
    "demo.launch(height=165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa48f660-0b95-42a2-b4d6-a5a10c331576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
