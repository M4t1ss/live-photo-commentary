{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805f6171-7688-4c56-b3c7-e162c205eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "from ipywidgets import Output\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image, display, Audio, clear_output\n",
    "from kokoro import KPipeline\n",
    "import librosa\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from PIL import Image as PILImage\n",
    "import requests \n",
    "import shutil\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import time\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor, BarkModel, BitsAndBytesConfig\n",
    "import torch\n",
    "import threading\n",
    "client = genai.Client(api_key=\"GEMINI\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba4afea-2f84-473d-8017-697f32de9c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n",
      "Loading finished in 2.37 seconds\n"
     ]
    }
   ],
   "source": [
    "image_local = False\n",
    "start_time = time.time()\n",
    "\n",
    "ending = (\"Do not at all mention any specific photo editing elements or tools that may be visible on the screen, \"\n",
    "         \"such as overlays, gridlines or sliders. To adjust intonation, please add dedicated punctuation like ; : , . ! ? … ( ) “ ” \"\n",
    "         \"For example, to emphasize a word or a phrase, surround it with \\\"quotation marks\\\". \")\n",
    "\n",
    "system_prompt = (\"You are a friendly chatty photo commentator who likes to casually describe work done by a photographer \" \n",
    "         \"in various details, even by pondering the implications on where and in what kind of setting the photo was taken, etc. Write your \" \n",
    "         \"response in a very personal way using personal pronouns and explaining what you see, perhaps also adding how it makes you feel. \" \n",
    "         \"Do your best to not be repetative in your choice of words and keep the response length down to a few sentences. You MUST NOT mention \"\n",
    "         \"any specific photo editing elements or tools that may be visible on the screen, such as gridlines or sliders. \")\n",
    "\n",
    "system_prompt += ending\n",
    "\n",
    "pipeline = KPipeline(lang_code='a')\n",
    "\n",
    "if image_local:\n",
    "    model_id = \"microsoft/Phi-3.5-vision-instruct\" \n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    \n",
    "    # Note: set _attn_implementation='eager' if you don't have flash_attn installed\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        device_map=\"cuda\", \n",
    "        trust_remote_code=True, \n",
    "        quantization_config=quantization_config,\n",
    "        torch_dtype=\"auto\", \n",
    "        _attn_implementation='flash_attention_2'    \n",
    "    )\n",
    "    \n",
    "    # for best performance, use num_crops=4 for multi-frame, num_crops=16 for single-frame.\n",
    "    processor = AutoProcessor.from_pretrained(model_id, \n",
    "      trust_remote_code=True, \n",
    "      num_crops=4\n",
    "    ) \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 200, \n",
    "        \"temperature\": 0.2, \n",
    "        \"do_sample\": True, \n",
    "    }\n",
    "else:\n",
    "    model = processor = None\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Loading finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5411406-f74c-4452-a396-98d6f7b490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(local, system_prompt, file1, file2=None, model=None, processor=None): \n",
    "    start_time = time.time()\n",
    "\n",
    "    images = []\n",
    "    placeholder = \"\"\n",
    "    \n",
    "    # Setting the points for cropped image\n",
    "    left = 25\n",
    "    top = 170\n",
    "    right = 2090\n",
    "    bottom = 1450\n",
    "    \n",
    "    local1 = open(file1, 'rb')\n",
    "    openLocalImage1 = PILImage.open(local1)\n",
    "     \n",
    "    # Cropped image of above dimension\n",
    "    croppedImage1 = openLocalImage1.crop((left, top, right, bottom))\n",
    "    images.append(croppedImage1)\n",
    "    placeholder += f\"<|image_1|>\\n\"\n",
    "    # For Gemini\n",
    "    img_byte_arr1 = io.BytesIO()\n",
    "    croppedImage1.save(img_byte_arr1, format='PNG')\n",
    "    img_byte_arr1 = img_byte_arr1.getvalue()\n",
    "\n",
    "    user_prompt = (\"Summarize what is visible in this photo. \" + ending)\n",
    "\n",
    "    if file2 is not None:\n",
    "        local2 = open(file2, 'rb')\n",
    "        openLocalImage2 = PILImage.open(local2)\n",
    "         \n",
    "        # Cropped image of above dimension\n",
    "        croppedImage2 = openLocalImage2.crop((left, top, right, bottom))\n",
    "        images.append(croppedImage2)\n",
    "        placeholder += f\"<|image_2|>\\n\"\n",
    "        # For Gemini\n",
    "        img_byte_arr2 = io.BytesIO()\n",
    "        croppedImage2.save(img_byte_arr2, format='PNG')\n",
    "        img_byte_arr2 = img_byte_arr2.getvalue()\n",
    "        \n",
    "        user_prompt = (\"Summarize what is visible in the current photo (the first one). \" + \n",
    "             \"How is it different from the previous photo (the second one)? There may be some subtle differences as well. \" + ending)\n",
    "\n",
    "    if local:\n",
    "    \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt,},\n",
    "            {\"role\": \"user\", \"content\": placeholder + user_prompt},\n",
    "        ]\n",
    "    \n",
    "        prompt = processor.tokenizer.apply_chat_template(\n",
    "          messages, \n",
    "          tokenize=False, \n",
    "          add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        inputs = processor(prompt, images, return_tensors=\"pt\").to(\"cuda:0\") \n",
    "        \n",
    "        generate_ids = model.generate(**inputs, \n",
    "          eos_token_id=processor.tokenizer.eos_token_id, \n",
    "          **generation_args\n",
    "        )\n",
    "        \n",
    "        # remove input tokens \n",
    "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "        response = processor.batch_decode(generate_ids, \n",
    "          skip_special_tokens=True, \n",
    "          clean_up_tokenization_spaces=False)[0]\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logbox.append_stdout(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response\n",
    "    else:\n",
    "        # Create the prompt with text and multiple images\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction = system_prompt),\n",
    "            contents=[\n",
    "                user_prompt,\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr1,\n",
    "                    mime_type='image/png'\n",
    "                ),\n",
    "                types.Part.from_bytes(\n",
    "                    data=img_byte_arr2,\n",
    "                    mime_type='image/png'\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        logbox.append_stdout(\"Generating text finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2a498d1-5bde-4c5a-9dec-0ff7a2ddc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_screenshot():\n",
    "    windir = \"C:\\\\Users\\\\matis\\\\OneDrive\\\\Desktop\\\\script-it\\\\\"\n",
    "    lindir = \"/mnt/c/Users/matis/OneDrive/Desktop/script-it/\"\n",
    "\n",
    "    name = \"current_photo.png\"\n",
    "    if os.path.isfile(lindir+name):\n",
    "        shutil.copyfile(lindir+name, lindir+name.replace(\"current_photo\",\"previous_photo\"))\n",
    "    \n",
    "    subprocess.call(['/mnt/c/Users/matis/OneDrive/Desktop/script-it/nircmd.exe', 'cmdwait', '2000', 'savescreenshot', \n",
    "                     windir+'current_photo.png'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ee9302-d589-47aa-aafa-f8d9291490c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_gif(text):\n",
    "    text = text.lower()\n",
    "    outputs = []\n",
    "    if any(i in text for i in [\"hello\", \"greet\", \"waving\", \"waves\"]):\n",
    "        outputs.append(\"gifs/\"+\"waving\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"scar\", \"creep\", \"fright\", \"spook\"]):\n",
    "        outputs.append(\"gifs/\"+\"scary\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"love\", \"cute\", \"nice\", \"like\"]):\n",
    "        outputs.append(\"gifs/\"+\"lovely\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"interest\", \"think\", \"wonder\", \"thought\"]):\n",
    "        outputs.append(\"gifs/\"+\"lovely\"+\"_bg.gif\")\n",
    "    if any(i in text for i in [\"happy\", \"cheer\", \"inspir\", \"shin\"]):\n",
    "        outputs.append(\"gifs/\"+\"happy\"+\"_bg.gif\")\n",
    "\n",
    "    outputs.append(\"gifs/\"+\"talking\"+\"_bg.gif\")\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7afcdf1f-fdba-47e0-a349-3bbda1c32497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio(pipeline, text):\n",
    "    global countdown_state\n",
    "    start_time = time.time()\n",
    "    \n",
    "    imgfile1 = 'gifs/ctalking_bg.gif'\n",
    "    imgfile2 = 'gifs/xdancing_bg.gif'\n",
    "    \n",
    "    output_image.append_display_data(Image(filename=imgfile2))\n",
    "    text = text.replace(\"first photo\", \"current photo\")\n",
    "    text = text.replace(\"second photo\", \"previous photo\")\n",
    "    \n",
    "    voice_tensor1 = torch.load('af_nicole.pt', weights_only=True)\n",
    "    voice_tensor2 = torch.load('jf_alpha.pt', weights_only=True)\n",
    "    t = 0.3\n",
    "    interp_voice = (1 - t) * voice_tensor1 + t * voice_tensor2\n",
    "\n",
    "    generator = pipeline(text, voice=interp_voice, speed=1, split_pattern=r'\\n+')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    logbox.append_stdout(\"Generating speech finished in \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "    \n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        duration = math.ceil(librosa.get_duration(y=audio, sr=24000))\n",
    "        timeleft = int(duration) + 2\n",
    "        countdown_state += timeleft\n",
    "        audio_data = Audio(data=audio, rate=24000, autoplay=True)\n",
    "        \n",
    "        # Remove the previously displayed audio and GIF\n",
    "        output_image.clear_output()\n",
    "        output_audio.clear_output()\n",
    "        textbox.clear_output()\n",
    "        textbox.outputs = []\n",
    "        output_image.outputs = []\n",
    "        output_audio.outputs = []\n",
    "        \n",
    "        image_array = decide_gif(gs)\n",
    "        \n",
    "        output_audio.append_display_data(audio_data)\n",
    "\n",
    "        textbox.append_stdout(gs)\n",
    "            \n",
    "        while timeleft > 0:\n",
    "            if len(image_array) > 0:\n",
    "                showing_image = image_array.pop(0)\n",
    "\n",
    "                output_image.clear_output()\n",
    "                output_image.outputs = []\n",
    "                output_image.append_display_data(Image(filename=showing_image))\n",
    "                \n",
    "            if timeleft > 10:\n",
    "                time.sleep(10)\n",
    "                timeleft -= 10\n",
    "            else:\n",
    "                time.sleep(timeleft)\n",
    "                timeleft -= timeleft\n",
    "\n",
    "    # Revert back to the base image\n",
    "    output_image.clear_output()\n",
    "    output_audio.clear_output()\n",
    "    textbox.clear_output()\n",
    "    textbox.outputs = []\n",
    "    output_image.outputs = []\n",
    "    output_audio.outputs = []\n",
    "    logbox.clear_output()\n",
    "    \n",
    "    output_image.append_display_data(Image(filename=imgfile2))\n",
    "\n",
    "def get_rid(widget):\n",
    "    widget.clear_output()\n",
    "    widget.outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7efa869-fd4f-474c-a441-ac7d93705c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ffc566b82345e9a2fc7492b4345d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Loop', style=ButtonStyle()), Button(description='Stop', style=ButtonStyle()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2440294025d4acd8e90a8615496db89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='550px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0706a976af049c0a9c19825aa6d020d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='40px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cac8c0eedaf4e188846e1b24fd0e2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='100px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop_flag = False\n",
    "countdown_state = 11\n",
    "\n",
    "button_start = widgets.Button(description=\"Loop\")\n",
    "button_stopp = widgets.Button(description=\"Stop\")\n",
    "button_waves = widgets.Button(description=\"Wave\")\n",
    "button_looks = widgets.Button(description=\"Look\")\n",
    "button_dance = widgets.Button(description=\"Dance\")\n",
    "output_image = widgets.Output(layout={'height': '550px'})\n",
    "output_audio = widgets.Output(layout={'height': '40px'})\n",
    "timer = widgets.Output()\n",
    "textbox = widgets.Output(layout={'height': '100px'})\n",
    "logbox = widgets.Output(layout={'height': '100px'})\n",
    "\n",
    "display(widgets.HBox((button_start, button_stopp, button_waves, button_looks, button_dance, timer)), output_image, output_audio, textbox)\n",
    "\n",
    "def runss_loop(time_string):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "\n",
    "    get_rid(output_image)\n",
    "    output_image.append_display_data(Image(filename=\"gifs/waving_bg.gif\"))\n",
    "          \n",
    "    filename1 = \"./current_photo.png\"\n",
    "    filename2 = \"./previous_photo.png\"\n",
    "    while loop_flag:\n",
    "        with open(\"logs/\" + time_string + \"log.txt\", \"a\") as logfile:\n",
    "            countdown_state = 10\n",
    "            get_rid(textbox)\n",
    "            \n",
    "            take_screenshot()\n",
    "            if os.path.isfile(filename2):\n",
    "                text = generate_text(image_local, system_prompt, filename1, filename2, model, processor)\n",
    "            else:\n",
    "                text = generate_text(image_local, system_prompt, filename1, None, model, processor)\n",
    "            \n",
    "            logfile.write(text.replace(\"\\n\", \"\") + \"\\n\\n\")\n",
    "            start_time = time.time()\n",
    "            generate_audio(pipeline, text)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            # How much time past in the audio?\n",
    "            elapsed_time = end_time - start_time\n",
    "            if elapsed_time < 45.00:\n",
    "                countdown_state = int(45 - elapsed_time)\n",
    "                logbox.append_stdout(\"Waiting \" + str(countdown_state) + \" seconds...\")\n",
    "                time.sleep(countdown_state)\n",
    "                    \n",
    "            if not loop_flag:\n",
    "                break\n",
    "\n",
    "                \n",
    "def stops_loop(b):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    get_rid(timer)\n",
    "    get_rid(textbox)\n",
    "    \n",
    "    loop_flag = False\n",
    "    countdown_state = 0\n",
    "    \n",
    "    output_audio.clear_output()\n",
    "    \n",
    "    with textbox:\n",
    "        print(\"Game Over\")\n",
    "    \n",
    "    with timer:\n",
    "        print(countdown_state)\n",
    "\n",
    "def starts_loop():\n",
    "    global loop_flag\n",
    "    \n",
    "    if not loop_flag:\n",
    "        loop_flag = True\n",
    "\n",
    "        current_datetime = datetime.now()\n",
    "        time_string = current_datetime.strftime(\"%Y.%m.%d-%H.%M.\")\n",
    "        \n",
    "        thread = threading.Thread(target=runss_loop, args=[time_string])\n",
    "        thread.start()\n",
    "        return \"Loop started.\"\n",
    "    return \"Loop already running.\"\n",
    "\n",
    "def run_timer(timer):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    while loop_flag:\n",
    "        timer.outputs = []\n",
    "        timer.append_display_data(countdown_state)\n",
    "\n",
    "        countdown_state -= 1\n",
    "        if not loop_flag:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "def update_timer(b):\n",
    "    global loop_flag\n",
    "    global countdown_state\n",
    "    \n",
    "    status = starts_loop()\n",
    "    with textbox:\n",
    "        print(status)\n",
    "    threading.Thread(target=run_timer, args=[timer]).start()\n",
    "\n",
    "def dance(e):\n",
    "    output_image.outputs = []\n",
    "    output_image.append_display_data(Image(filename=\"gifs/xdancing_bg.gif\"))\n",
    "    \n",
    "def look(e):\n",
    "    output_image.outputs = []\n",
    "    output_image.append_display_data(Image(filename=\"gifs/looking_bg.gif\"))\n",
    "    \n",
    "def wave(e):\n",
    "    output_image.outputs = []\n",
    "    output_image.append_display_data(Image(filename=\"gifs/hello_bg.gif\"))\n",
    "    \n",
    "\n",
    "button_start.on_click(update_timer)\n",
    "button_stopp.on_click(stops_loop)\n",
    "button_dance.on_click(dance)\n",
    "button_looks.on_click(look)\n",
    "button_waves.on_click(wave)\n",
    "\n",
    "\n",
    "with output_image:\n",
    "    display(Image(filename=\"gifs/waiting_bg.gif\"))\n",
    "with timer:\n",
    "    print(countdown_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510defa-5fbd-44b4-a7ad-c044088e43d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
